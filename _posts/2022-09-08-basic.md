---
layout: post
title: "내가 보려고 정리한 데이터분석 기본 5"
subtitle: 데이터 분석
categories: project
tags: [data analysis]
---

# DataFrame에 함수를 적용

## apply()

Serires, Series -> 연산(expression)
Series/Series -> 연산이상의 제어(분기, 반복, 대입)이 필요한 경우(statement)

### expression과 statement의 차이

statement : simple statement, compound statement
simple statement : 콜론을 사용한 블럭을 생성할 수 없는 것
- break, continue, return, raise
compound statement : 콜론을 사용한 블럭 생성을 할 수 있는 것
- if, for, while, def, class, try, with
- = (assignment), +=, -=, (augmented assignment)-연산하고 대입

expression(simple statement 중에 하나)

expression : 1개의 type을 가지고 있다.(object이다)

      [1,2,3] -> object
      (1,2,3), {1,2,3}, {'A':1,'B':2,'C':3}, 123, 3.14, True/False
      abs(), sum(), max()... 함수 호출, list.append()...
      A+B, A-B, A**2, A>B... 각종 연산...(결과가 expression)
      'A' if a > 10 .. conditional expression
      lambda x : x**2 -> lambda expression
      [x**2 for x in range(5) if x%2==0] -> comprehension
      A := 10 -> assignment expression
      ➡️ 모두 expression 이라고 한다.

Series.replace(before, after) : before를 찾아 after로 변경

before, after : 스칼라이거나 목록일 수 있다.

Series.replace(dict) : key-before, value-after인 item을 갖는 dict사용

두가지 방법이 동일하다는 것을 알아야 한다.
```python
who_dict = {'man':'남자','woman':'여자','child':'아이'}
df['who'].replace(who_dict).head(5)

def transform_who(x):
    return '남자' if x=='man' else '여자' if x=='woman' else '아이'
df['who'] = df['who'].apply(transform_who)
```

apply에는 lambda 함수도 사용이 가능하다

```python
df['survived'].apply(lambda x : '생존' if x ==1 else '사망')
```

### Regex를 사용하자

```python
s = pd.Series(['man-child','woman-child'])
before = ['man','woman','child']
after = ['남자', '여자', '아이']
s.replace(before, after).head(2)

s = pd.Series(['man-child','woman-child'])
before = ['^man','woman','child']
after = ['남자', '여자', '아이']
s.replace(before, after,regex=True).head(2)
```

## Group by 대신 pivot table
차이점을 찾아보자
```python
# index로 'who', values로 'survived' 사용한 피벗테이블 생성
df.groupby('who')[['survived']].mean()
```

|index|values|aggfunc|
|---|---|---|
|who|survived|mean|

**이대로 pivot_table에 적용한다면**
```python
df.pivot_table(index='who', values='survived', aggfunc='mean')

df.pivot_table(index=['who','pclass'],values='survived')

df.pivot_table(index='who', columns='pclass', values='survived')
# group by로 해보기
df.groupby(by=['who','pclass'])['survived'].mean().unstack()


df.pivot_table(index = 'who', columns='pclass', values='survived', aggfunc=['sum','mean'])
```

## 파일 읽기 심화

glob를 활용하자
```python
# 파일 목록 가져오는 모듈
import glob
# '.' : 아무거나 한글자(1개)
# '?' : 아무거나 여러글자(0개 이상)
#  [123] : 1,2,3중하나, (괄호에 있는 문자 중 하나)
df_list = [pd.read_csv(filename, encoding='euc-kr') for filename in glob.glob('data/gas*.csv')]
pd.concat(df_list, ignore_index=True)
```

## 파일 연결하기

> 인덱스가 동일할 때 권장

행방향으로 연결
```python
pd.concat([gas1, gas2])
```
열방향으로 연결
```python
pd.concat([gas1, gas2], axis=1)
```

concat은 outer로 default로 되어 있다.

concat은 무한정 파일을 연결할 수 있지만 merge는 두개의 파일을 연결할 수 있다.

> 서로 다른 구성의 DataFrame이지만 공통된 key값을 가지고 있다면 연결 가능하다.

```python
# 고객명을 기준으로 하나의 행으로 만들기(merge)
pd.merge(df1, df2, on='고객명')
# 기준을 왼쪽으로 보고 왼쪽의 것은 가져오고
# 오른쪽 테이블은 조건에 맞는 것만
pd.merge(df1, df2, how='left')
# 기준을 오른쪽으로 보고 오른쪽의 것은 가져오고
# 왼쪽 테이블은 조건에 맞는 것만
pd.merge(df1, df2, how='right')

# 지정한 컬럼을 drop하기 싫을 때
pd.merge(df1, df2, left_on='이름', right_on='고객명')

# 컬럼 버리기
pd.merge(df1, df2, left_on='이름', right_on='고객명').drop('고객명', axis=1)

```