---
layout: post
title: "내가 보려고 정리한 데이터분석 기본 3"
subtitle: 데이터 분석
categories: project
tags: [data analysis]
---

# 타이타닉

seaborn이 제공하는 대표적인 dataset

```python
import seaborn as sns
df = sns.load_dataset("titanic")
```
/+ 저번에 배운 저장방식과 함께 생각해본다면
```python
df.to_csv('titanic.csv', index=False) # (숫자, 문자열은 인지하나 날짜/시간, Category, timedelta는 인지하지 못한다.)
df.to_excel('titanic.xlsx', index=False)
```

```python
import shelve
#with를 사용하면 자동으로 읽기+쓰기 용으로 파일을 연다.
#쓰기
with shelve.open('kb_data') as data:
    data['titanic'] = df
#읽기
with shelve.open('kb_data') as data:
    df = data['titanic']
```
> 중간 중간 파일의 버전을 만들어 놓자.

### dir 명령어
```python
with shelve.open('kb_data') as data:
    print(data.keys()) # 출력이 되지 않는다..
    print(dir(data.keys())) # -> 사용방법을 알 수 있다.
```

##  데이터 요약

```python
#앞에서 5개
df.head(5)

#뒤에서 5개
df.tail(5)
```
### df.info() 
컬럼별 정보, 데이터 개수, 데이터 타입를 알려준다.
- 결측치 여부 : 결측치가 있는 경우 해결해야한다.
- columns에 대한 각 dtype 확인 : numeric이 아닌 것을 numeric으로 변경해야함(int, float)
-> info로 확인하고 이 두가지 작업을 수행해줘야 한다.

### 범주형 변수

- encoding 필요( 머신, 딥러닝 에서는 숫자가 아닌 것을 숫자로 변경하는 것을 의미)
- 문자 인코딩 - 사용자가 입력한 문자나 기호들을 컴퓨터가 이용할 수 있는 신호로 만들기
    - label encoding : 0, 1, 2, 3... 의 일련의 숫자로 변환
    - one hot encoding : 범주의 수 만큼 dummy 변수를 생성, 변수 중에서 1개만 1로 표현, 나머지 0으로 표현


|encoding 정리|||
|---|---|---|
|who|label encoding|one hot encoding|
|'man'|1|1 0 0|
|'woman'|2|0 1 0|
|'child'|0|0 0 1|
|'man'|1|1 0 0|
|'woman'|2|0 1 0|

```python
# label encoding
temp = pd.DataFrame()
temp['who'] = ['man', 'woman', 'child', 'man', 'woman']
temp['who_label_encoding'] = temp['who'].astype('category').cat.codes

# one hot encoding
dummy = pd.get_dummies(temp['who'])
temp2 = pd.concat([temp, dummy], axis=1)
display(temp, temp2)
```
출력

![example](/assets/img/0906/encoding.png)


### 연속형, 범주형(이산형)의 차이
- 연속형
    - A, B의 값을 알때, A=10, B=20일 경우 예측값이 데이터를 더 수집했을 때의 값을 C 라고 했을때
    - 이때 C가 A보다 작거나 B보다 크거나 A~B사이 값이 나와도 될 때

- 범주형(이산형)
    - A,B 값이 있을 때, 예측값이 데이터를 더 수집했을 때의 값을 C 라고 했을 때
    - C는 A 또는 B인 경우
```python
df.info()
df.info(memory_usage='deep')#메모리 사용량을 자세히 알고싶을 때

#각 컬럼에 대한 요약 통계
df.describe()

#컬럼별 분포를 확인할 때.
df['who'].value_counts() # 결과가 Series
df['who'].value_counts().to_frame() # 결과가 DataFrame
df.groupby(['who','survived'])['who'].count()

df.ndim
df.shape
df.index
df.columns
df.values
df.T #행과 열을 바꾸기 df.transpose()
df['plcass']
```
### 검정하기

- 범주형 - 범주형 두개의 변수는 독립인가 종속인가
- 카이 제곱 검정
- 귀무 가설 : 두 변수의 관계는 독립이다
- 대립 가설 : 두 변수의 관계는 독립이 아니다.
- 귀무 가설을 기각하고 대립 가설을 채택했을 때 잘못 판단이 되었을 확률 p-value(제 1종 오류)

- 관계 분석하기
    - p < 0.05 일때 두 변수는 독립이 아닌 관계가 있는 것 
        - p 값이 작을 수록 가설이 옳다.

    - t-test : 연속값에 대해 범주별(그룹별)로 차이가 있는지 검정(2개 그룹, sample 수가 많지 않을 때)
    - oneway anova test : 연속값에 대해 범주별(그룹별)로 차이가 있는지 검정 (2개 이상)
    - chi-square test : 두개의 범주변수에 대해 두 변수의 독립성 검정

### 타입 변경하기

> df의 'pclass' column에 대해 'int32'로 데이터 타입을 변경하고 앞에서부터 5개 데이터를 출력합니다.
```python
s1 = pd.Series([-128,-127,127,128], dtype='int8')
s2 = pd.Series([-128,-127,127,128]).astype('int8') #overflow
display(s1,s2)
```
타입에 따라서 overflow가 나타날 수 있다는 생각을 해야한다.


float 32로 바꾸기
```python
#float32
df['pclass'].astype(np.float32).head(5) 

#object로 변경
# df['pclass'].astype('object').head(5) -> object로 바뀐다, 원하는 타입으로 변경된 것은 X
df['pclass'].astype('str').head(5)

#category로 변경
#메모리를 절약할 수 있다.
df['pclass'].astype('category').head(5)

df['embark_town'].info(memory_usage='deep')
df['embark_town'].astype('category').info(memory_usage='deep')
```

### 정렬하기

sort_index: index 정렬
- index 기준으로 정렬 기본 오름차순
- 내림차순 정렬을 적용하려면, `ascending=False` 옵션 설정

```python

#생략 = axis=0
temp = df.sample(frac=0.1) # 10%만 랜덤으로 샘플 뽑기
temp.sort_index().head(5) # 오름차순 정렬하고 앞에서 5개 뽑기
temp.sort_index(ascending=False).head(5) # 내림차순 정렬하고 앞에서 5개 뽑기

# columns 기준을 axis = 1
temp.sort_index(axis=1).head(5) # 오름차순 정렬하고 앞에서 5개 뽑기
temp.sort_index(axis=1 , ascending=False).head(5) # 내림차순 정렬하고 앞에서 5개 뽑기
```

sort_values: 값에 대한 정렬
- 값을 기준으로 행을 정렬
- by에 기준이 되는 행을 설정
- by에 2개 이상의 컬럼을 지정하여 정렬가능
- 오름차순/내림차순을 컬럼 별로 지정가능

```python
df.sort_values(by='age', ascending=True, ignore_index=False).head() # 오름차순 + 'age'컬럼 기준, 인덱스를 표시한다.
df.sort_values(by='age', ascending=False, ignore_index=True).head() # 내림차순 + 'age'컬럼 기준, 인덱스를 표시하지 않는다.
```

카테고리의 정렬 순서를 알고 싶을 때 
> df['컬럼명'].unique() 으로 사용한다.

다중 칼럼 정렬
```python
# 우선 fare로 정렬하고 동일할 경우 age로 정렬하기
df.sort_values(by=['fare','age'])
# fare를 내림 차순으로 정렬, 동일할 경우 age로 오름 차순 정렬
df.sort_values(by=['fare','age'], ascending=[False, True])
```

|Basic Indexing||
|---|---|
|single element indexer|column label|
|index array indexer|column label|
|`boolean array indexer`|`row 개수`|
|`slice indexer`|`row label`|

```python
# index가 5, columns가 'class'인 것에 대한 데이터를 조회
df.loc[5, 'class']
# index가 2~5인 것에 대해 columns 중 'age', 'fare', 'who'에 대한 데이터를 조회
# loc으로 하기 때문에 2:5로 해도 2부터 5까지가 적용된다.
df.loc[2:5,['age','fare','who']]
# columns의 slicing 적용
df.loc[2:5,'class':'deck']
```

Selection by Label, Selection by Integer
- column_indexer는 생략 가능'
```python
df.loc[:,'A'] #추천
df.loc['A']
df.loc['A',]
```

조건문 활용
```python
condition = df['who']=='man'
df[condition]

condition1 = (df['fare'] > 30)
condition2 = (df['who'] == 'woman')

df.loc[condition1 & condition2]
df.loc[condition1 | condition2]

#20~40세의 pclass가 1또는 2의 survived,pclass,age,fare만 10개 출력
df.loc[(df['age'] >= 20) & (df['age']< 40) & ((df['pclass'] == 1) | (df['pclass'] == 2)),['survived','pclass','age','fare']].head(10)

df['pclass'].unique() 으로 도메인 확인하기.
```

```python
# iloc 활용법
df.iloc[1, 3]
df.iloc[[0, 3, 4], [0, 1, 5, 6]]
df.iloc[:3, :5]

# at을 사용해 시간을 줄일 수 있지만 권장 X
%timeit df.loc[0, 'fare']
%timeit df.at[0, 'fare']

%timeit df.iloc[0, 5]
%timeit df.iat[0, 5]
```

조건문활용
```python
df['fare'].where(df['fare']<20, 0).tail(10)
# 20보다 작은것은 그대로, 크거가 같은 것은 0으로 바꾸기

sample = pd.DataFrame({'name': ['kim', 'lee', 'park', 'choi'], 
                        'age': [24, 27, 34, 19]
                      })
# 도메인에 포함되는지 확인하기
df.loc[sample['name'].isin(['kim', 'lee'])]
```
## 통계

개수(도수) 세기

```python
# 열에대한 
df.count(axis=0)
# 행에 대한
df.count(axis=1)
#컬럼별
df['age'].count()
```

평균 구하기
```python
# 만약 nominal data일 경우 평균을 구할 수 없으므로 출력되지 않는다.
# 열에대한 
df.mean(axis=0)
# 행에 대한
df.mean(axis=1)
#컬럼별
df['age'].mean()
# numeric data만
df.mean(numeric_only=True)
# NaN값 제외
df.mean(skipna=True)

# 조건문과 함께

df.loc[df['adult_male']==True].mean()
```

중앙값
- outlier가 있을 경우 median을 대표값으로 더 선호
```python
# 홀수개
-> 3
pd.Series([1, 2, 3, 4, 5]).median()
# 짝수개
-> 3,4
pd.Series([1, 2, 3, 4, 5, 6]).median()
```

합계
```python
df['fare'].sum()
```

누적합
```python
df['age'].cumsum()
```

누적곱
```python
df['age'].cumprod()
```

분산
```python
((df['fare'].values - fare_mean) ** 2).sum() / (df['fare'].count() - 1)
df['fare'].var()
# 모분산
df['fare'].var(ddof=0)
# 표준편차
np.sqrt(my_var)
df['fare'].std()
```

최대, 최소

```python
df['age'].min()
df['age'].max()
```

분위(quantile)
```python
# 10%의 분위
df['age'].quantile(0.1)
# IQR 구하기
Q1, Q3 = df['age'].quantile([0.25, 0.75])
IQR = Q3 - Q1

# lower보다 낮거나 upper 보다 높은 값은 통계적으로 의미가 없음
lower_fence = Q1 - (IQR * 1.5)
upper_fence = Q3 + (IQR * 1.5)
print(IQR, lower_fence, upper_fence)
```

고유값, 고유값 개수, 최빈값, 상관관계
```python
# 고유값
df['who'].unique()
# 고유값 개수
df['who'].nunique()
# 최빈값
df['who'].mode()
# 각 column 사이의 상관 관계
df.corr()
# 생존자 상관관계
df.corr()['survived']
```